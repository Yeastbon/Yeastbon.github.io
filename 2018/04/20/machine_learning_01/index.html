<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>机器学习笔记01 | 一个还没有想好叫什么名字的博客</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">机器学习笔记01</h1><a id="logo" href="/.">一个还没有想好叫什么名字的博客</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">机器学习笔记01</h1><div class="post-meta">Apr 20, 2018</div><div class="post-content"><blockquote>
<p>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experierce E.</p>
</blockquote>
<p>上面这段的引述来自Tom Mitchell(1998)，说句实话，我并不知道Tom Mitchell是谁，但是这个机器学习的定义给出的足够精美，所以我拿来做了个题注。这周我开始学习了Coursera上的机器学习课程，老师是传说中的Andrew Ng——吴恩达，老师的讲述方式深得我这种学渣的喜爱，连一个最最基础的矩阵乘法也专门拿出一节课来讲解，这门课对数学的要求真的是很低了。经过我的总结，我把第一周的内容分成了以下两个部分：</p>
<ol>
<li><p>Introduction</p>
</li>
<li><p>Gradient Descent Algorithm</p>
</li>
</ol>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="definition"><a href="#definition" class="headerlink" title="definition"></a>definition</h3><p>首先给出了机器学习的两个定义，第一个定义是由Arthur Samuel(1959)给出的：</p>
<blockquote>
<p>the field of study that gives computers the ability to learn without being explicitly programed.                  </p>
</blockquote>
<p>第二个定义就是前文提到的那个为了押韵故意让我们这等英语不好的学生蒙圈的定义，但我觉得它很优美。</p>
<h3 id="机器学习的应用"><a href="#机器学习的应用" class="headerlink" title="机器学习的应用"></a>机器学习的应用</h3><ul>
<li>数据挖掘</li>
<li>自动驾驶</li>
<li>字迹识别</li>
<li>自然语言处理</li>
<li>计算机视觉</li>
<li>商品推荐</li>
<li>最终实现人工智能</li>
</ul>
<h3 id="Supervised-learning–”right-answer”-is-given"><a href="#Supervised-learning–”right-answer”-is-given" class="headerlink" title="Supervised learning–”right answer” is given"></a>Supervised learning–”right answer” is given</h3><p>In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.<br>监督学习处理的问题可以被分为两类：</p>
<ol>
<li>regression</li>
<li>classification</li>
</ol>
<h4 id="regression-problem"><a href="#regression-problem" class="headerlink" title="regression problem"></a>regression problem</h4><p>回归问题的目标是找到输入和输出之间的映射关系，简而言之就是得到一个函数，用以通过给定的输入来预测输出，输出量是连续的。一个很好的例子是，通过某地区房子的面积来估算房子的售价，这个例子也被用于后面的更具体的内容。</p>
<h4 id="classification-problem"><a href="#classification-problem" class="headerlink" title="classification problem"></a>classification problem</h4><p>分类问题的输出量是离散的。一个最简单的例子就是通过肿瘤的大小来和肿瘤是否为恶性的关系来让程序预测肿瘤是否为恶性，在这个例子里，输出量只有0和1。当然实际的例子中可能不止有两个输出量。</p>
<h3 id="Unsupervised-learning"><a href="#Unsupervised-learning" class="headerlink" title="Unsupervised learning"></a>Unsupervised learning</h3><p>在无监督学习中，我们并不知道结果应该是什么样子的，通过挖掘数据内在的关系来得到结果，当然这部分我的理解还很差，学到这部分的时候我再来补充。</p>
<h4 id="examples"><a href="#examples" class="headerlink" title="examples"></a>examples</h4><p>Clustering: Take a collection of 1,000,000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different variables, such as lifespan, location, roles, and so on.</p>
<p>Non-clustering: The “Cocktail Party Algorithm”, allows you to find structure in a chaotic environment. (i.e. identifying individual voices and music from a mesh of sounds at a cocktail party).</p>
<h2 id="Gradient-Descent-Algorithm"><a href="#Gradient-Descent-Algorithm" class="headerlink" title="Gradient Descent Algorithm"></a>Gradient Descent Algorithm</h2><p>首先要研究的是监督学习中的回归问题，还是从预估房价这个问题来引入具体算法的学习。主要的思想是：通过算法对训练集的学习，得到一个输入和输出之间的映射关系，图示如下：</p>
<div id="flowchart-0" class="flow-chart"></div><br>通过得到的h(x)我们就可以愉快地利用房屋的面积来预估售价了：<br><div id="flowchart-1" class="flow-chart"></div>

<h3 id="hypothesis"><a href="#hypothesis" class="headerlink" title="hypothesis"></a>hypothesis</h3><p>h(x)的英文名称为hypothesis，可以将其理解为一个函数。至于为什么没有用通用的f(x)来表示，我认为是由于hypothesis更能表示预测，估计这样的一个含义。在这个例子中，我们可以假设房价和面积存在一次函数的关系，所以可以把h(x)表示为：</p>
<p>$$<br>h_{\theta}(x) = \theta_0 + \theta_1x<br>$$</p>
<p>到了这一步，我们的主要问题自然而然的就转移到了如何选择$\theta_0$和$\theta_1$使得我们的$h(x)$函数拟合每一个数据点的效果最好。所以我们要引入cost function。</p>
<h3 id="cost-function"><a href="#cost-function" class="headerlink" title="cost function"></a>cost function</h3><p>cost function的表达式如下：</p>
<p>$$<br>J(\theta_0, \theta_1) = \frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2<br>$$<br>我们的目标就是使$J(\theta_0, \theta_1)$最小，而使$J(\theta_0, \theta_1)$最小的$\theta_0$和$\theta_1$就是我们的目标。这里需要说明的是，$h(x)$是以$x$为自变量的函数，$\theta_0$和$\theta_1$只是该函数的参数，而$J(\theta_0, \theta_1)$是以$\theta_0$和$\theta_1$为自变量的，这点一定不要搞混。</p>
<p>由于$\theta_0$和$\theta_1$两个自变量在代价函数中都含有平方项，所以该函数的数学图像会是一个二维等势线图。</p>
<h3 id="Gradient-descent-algorithm"><a href="#Gradient-descent-algorithm" class="headerlink" title="Gradient descent algorithm"></a>Gradient descent algorithm</h3><p>下面就是求使得$J(\theta_0, \theta_1)$为最小的$\theta_0$和$\theta_1$的办法：</p>
<ol>
<li>从某一个点$(\theta_0, \theta_1)$开始</li>
<li>持续改变$\theta_0$和$\theta_1$的值，使得$J(\theta_0, \theta_1)$逐渐减小，直到$J(\theta_0, \theta_1)$最终在最小值处收敛</li>
</ol>
<p>具体公式如下：<br>$$<br>\theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta_0, \theta_1)<br>$$<br>其中，$:=$表示赋值，$j$的取值分别为0和1。该算法的具体操作过程是，不断重复该公式使得$J(\theta_0, \theta_1)$不断减小，最终达到收敛。</p>
<p>这个算法还有几个问题需要说明，首先，两个参数的更新要同时进行，不能更新了$\theta_0$，然后再使用更新过的$\theta_0$来更新$\theta_1$，也就是说计算结果需要保存在其他的临时变量中，两个参数都计算完毕之后再<strong>同时</strong>更新两个参数。</p>
<p>还有一点就是，$\alpha$被称为learning rate，这个参数的选取十分重要。这个参数如果过小，可能会是收敛的过程很慢，而如果参数选择过大，有可能会使算法最终无法收敛。另外，$\alpha$并不需要随着计算的过程逐渐变小，因为随着计算的过程，导数项会越来越小，可以做到越靠近收敛点代价函数减小的幅度也随之变小，因此$\alpha$可以保持一个固定的值不变。</p>
<p>如下图所示，有的代价函数可能存在很多的极值点，我们的算法实际上的作用是找到极值，而非最值，因此我们有可能会通过不同的初值的选择而得到不同的结果。<br><img src="01.png" alt="lacal minimum 1"><br><img src="02.png" alt="lacal minimum 2"></p>
<p>经过求导运算，对于$\theta_0$和$\theta_1$可以给出更加具体的表达式：<br>$$<br>\begin{equation}\begin{split}<br>\frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1)&amp;=\frac{1}{m}\sum_{i=1}^m(h(x^{(i)})-y^{(i)})\\<br>\frac{\partial}{\partial\theta_1}J(\theta_0,\theta_1)&amp;=\frac{1}{m}\sum_{i=1}^m(h(x^{(i)})-y^{(i)})x^{(i)}<br>\end{split}\end{equation}<br>$$</p>
<p>以上就是第一个机器学习算法的全部内容，这个算法被称为”Batch” gradient descent algorithm，”Batch”体现了这个算法的一个缺点，那就是，每一次的梯度下降的过程，都需要使用所有全部的训练集，计算量很大。</p>
<h2 id="线性代数的复习"><a href="#线性代数的复习" class="headerlink" title="线性代数的复习"></a>线性代数的复习</h2><p>第一周课程的最后，复习了线性代数的基本知识，主要复习的内容有：矩阵，向量的概念及基本运算，矩阵的逆运算和转置运算。</p>
<p>通过矩阵的乘法可通过一步运算(一行代码)，就实现整个训练集的运算，我们调用的矩阵运算的函数还能通过并行计算等技术，提高计算性能，因此使用矩阵运算不仅仅有减少代码量的好处，而且还能提高计算效率。</p>
<p>由于这部分的主要的只是都是线性代数最最基础的知识，因此在这里就不多赘述了。<script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">tr=>start: Training Set
le=>start: Learning Algorithm
h=>start: h(x)
tr->le->h</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script><textarea id="flowchart-1-code" style="display: none">size=>start: size of house
h=>start: h(x)
price=>start: estimated price
size(right)->h(right)->price</textarea><textarea id="flowchart-1-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-1-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-1", options);</script></p>
</div><div class="tags"></div><div class="post-nav"><a class="next" href="/2018/04/19/hello/">Hello World</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/04/20/machine_learning_01/">机器学习笔记01</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/19/hello/">Hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">一个还没有想好叫什么名字的博客.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>